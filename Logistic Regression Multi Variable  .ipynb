{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Give your input for x and y values\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_iris\n",
    "x, y = load_iris(return_X_y = True)\n",
    "\n",
    "m = len(y)\n",
    "n = len(x[0])\n",
    "\n",
    "# initializing weights and bias as 0\n",
    "\n",
    "w = np.zeros(x.shape[1])\n",
    "b = 0\n",
    "\n",
    "# Total numbers of iterations to perform\n",
    "\n",
    "iteration = 3000\n",
    "\n",
    "# Learning rate alpha\n",
    "\n",
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.9 3.  1.4 0.2] 0 150 4\n"
     ]
    }
   ],
   "source": [
    "print(x[1], y[1], m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Our Logistic Regression Model\n",
    "\n",
    "def model(x,w,b):\n",
    "    LinReg = np.dot(x,np.transpose(w))+b\n",
    "    return 1/(1+np.exp(-LinReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Our Cost Function \n",
    "\n",
    "def cost_function():\n",
    "    value = 0\n",
    "    for i in range(m):\n",
    "        value += -y[i] * np.log(model(x[i], w,b)) - (1-y[i]) * np.log(1-(model(x[i],w,b)))\n",
    "    \n",
    "    return value/(2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_b(w,b):\n",
    "    value = 0 \n",
    "    for i in range(m):\n",
    "            value += (model(x[i],w,b) - y[i])\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent is same as MultiVariable Linear Regression. \n",
    "\n",
    "def gradient_decent():\n",
    "    global b\n",
    "    global w\n",
    "\n",
    "    for i in range(iteration):\n",
    "        tempw = w\n",
    "   \n",
    "  \n",
    "        for j in range(n):\n",
    "\n",
    "            derivative_val_w = 0 \n",
    "\n",
    "            for k in range(m):\n",
    "           \n",
    "           \n",
    "            \n",
    "              derivative_val_w += (model(x[k],w,b) - y[k])*x[k][j]\n",
    "\n",
    "            w[j] = w[j] - alpha*(derivative_val_w/m)\n",
    "            \n",
    "        \n",
    "        tempb = b \n",
    "        b = tempb - alpha *((update_b(tempw,tempb))/m)\n",
    "        if i% math.ceil(iteration / 10) == 0:\n",
    "        \n",
    "          print(f\" iterations:  \" +str(i) + f\" cost : {cost_function():8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feroz\\AppData\\Local\\Temp\\ipykernel_9872\\789849950.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  value += -y[i] * np.log(model(x[i], w,b)) - (1-y[i]) * np.log(1-(model(x[i],w,b)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iterations:  0 cost :     -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Feroz\\AppData\\Local\\Temp\\ipykernel_9872\\789849950.py:6: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  value += -y[i] * np.log(model(x[i], w,b)) - (1-y[i]) * np.log(1-(model(x[i],w,b)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iterations:  300 cost :      nan\n",
      " iterations:  600 cost :      nan\n",
      " iterations:  900 cost :      nan\n",
      " iterations:  1200 cost :      nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\p\\Machine  Learning Practice\\Logistic Regresssion .ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gradient_decent()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(w)\n",
      "\u001b[1;32mg:\\p\\Machine  Learning Practice\\Logistic Regresssion .ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     derivative_val_w \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m       derivative_val_w \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (model(x[k],w,b) \u001b[39m-\u001b[39m y[k])\u001b[39m*\u001b[39mx[k][j]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     w[j] \u001b[39m=\u001b[39m w[j] \u001b[39m-\u001b[39m alpha\u001b[39m*\u001b[39m(derivative_val_w\u001b[39m/\u001b[39mm)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m tempb \u001b[39m=\u001b[39m b \n",
      "\u001b[1;32mg:\\p\\Machine  Learning Practice\\Logistic Regresssion .ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel\u001b[39m(x,w,b):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     LinReg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(x, w)\u001b[39m+\u001b[39mb\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/p/Machine%20%20Learning%20Practice/Logistic%20Regresssion%20.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m+\u001b[39mnp\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mLinReg))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "gradient_decent()\n",
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRG = linear_model.LogisticRegression(\n",
    "   random_state = 0,solver = 'liblinear',multi_class = 'auto'\n",
    ").fit(x, y)\n",
    "LRG.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "proba= (model(x[5],w,b))\n",
    "if proba< 0.50:\n",
    "    print(0)\n",
    "else:\n",
    "    print(1)\n",
    "print(LRG.predict([x[5]]))\n",
    "print(y[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
